{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMc4rT/9wkrG5IbUVyatXYX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_xq-nhLYI5l","executionInfo":{"status":"ok","timestamp":1743259819372,"user_tz":-60,"elapsed":11114,"user":{"displayName":"Sebastian Steininger","userId":"02820484620863115156"}},"outputId":"29674477-809d-4ab5-b597-cee9654488a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ergebnisse für Decision Tree:\n","Accuracy: 0.9021 (+/- 0.0607)\n","Precision: 0.8999 (+/- 0.0640)\n","Recall: 0.8943 (+/- 0.0690)\n","F1-Score: 0.8911 (+/- 0.0662)\n","\n","\n","Ergebnisse für Random Forest:\n","Accuracy: 0.9599 (+/- 0.0300)\n","Precision: 0.9636 (+/- 0.0292)\n","Recall: 0.9527 (+/- 0.0323)\n","F1-Score: 0.9558 (+/- 0.0309)\n","\n","\n"]}],"source":["import numpy as np\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.model_selection import KFold\n","\n","# Lade den Datensatz\n","data = load_breast_cancer()\n","X, y = data.data, data.target\n","\n","# Teile den Datensatz in Trainings-, Test- und Validierungsdatensätze auf\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","# Definiere die Anzahl der Folds für die Kreuzvalidierung\n","N_SPLITS = 10\n","kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n","\n","# Initialisiere die Klassifikatoren\n","dt_clf = DecisionTreeClassifier(random_state=42, max_depth=5)\n","rf_clf = RandomForestClassifier(random_state=42)\n","\n","# Eigene Scorer-Funktionen mit zero_division=1\n","def precision_scorer(y_true, y_pred):\n","    return precision_score(y_true, y_pred, average='macro', zero_division=1)\n","\n","def recall_scorer(y_true, y_pred):\n","    return recall_score(y_true, y_pred, average='macro', zero_division=1)\n","\n","def f1_scorer(y_true, y_pred):\n","    return f1_score(y_true, y_pred, average='macro', zero_division=1)\n","\n","# Funktion zur Kreuzvalidierung\n","def evaluate_model(model, X, y):\n","    accuracy = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n","    precision = cross_val_score(model, X, y, cv=kf, scoring=make_scorer(precision_scorer))\n","    recall = cross_val_score(model, X, y, cv=kf, scoring=make_scorer(recall_scorer))\n","    f1 = cross_val_score(model, X, y, cv=kf, scoring=make_scorer(f1_scorer))\n","\n","    return {\n","        \"Accuracy\": (accuracy.mean(), accuracy.std()),\n","        \"Precision\": (precision.mean(), precision.std()),\n","        \"Recall\": (recall.mean(), recall.std()),\n","        \"F1-Score\": (f1.mean(), f1.std())\n","    }\n","\n","# Modelle bewerten\n","dt_results = evaluate_model(dt_clf, X_train, y_train)\n","rf_results = evaluate_model(rf_clf, X_train, y_train)\n","\n","# Ergebnisse ausgeben\n","def print_results(name, results):\n","    print(f\"Ergebnisse für {name}:\")\n","    for metric, (mean, std) in results.items():\n","        print(f\"{metric}: {mean:.4f} (+/- {std:.4f})\")\n","    print(\"\\n\")\n","\n","print_results(\"Decision Tree\", dt_results)\n","print_results(\"Random Forest\", rf_results)"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n","\n","# Trainiere das Random Forest Modell mit dem gesamten Trainings- und Validierungsdatensatz\n","rf_clf.fit(X_train, y_train)\n","\n","# Definiere die Anzahl der Bootstrap-Samples\n","n_bootstrap_samples = 1000\n","\n","# Initialisiere Listen für die Metriken\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","f1_scores = []\n","\n","# Bootstrap-Schleife\n","for _ in range(n_bootstrap_samples):\n","  # Erstelle ein Bootstrap-Sample aus dem Testdatensatz\n","  bootstrap_indices = np.random.choice(len(X_test), size=len(X_test), replace=True)\n","  X_bootstrap = X_test[bootstrap_indices]\n","  y_bootstrap = y_test[bootstrap_indices]\n","\n","  # Berechne die Vorhersagen mit dem trainierten Modell\n","  y_pred = rf_clf.predict(X_bootstrap)\n","\n","  # Berechne die Metriken für das Bootstrap-Sample\n","  accuracy_scores.append(accuracy_score(y_bootstrap, y_pred))\n","  precision_scores.append(precision_score(y_bootstrap, y_pred, average='macro', zero_division=1))\n","  recall_scores.append(recall_score(y_bootstrap, y_pred, average='macro', zero_division=1))\n","  f1_scores.append(f1_score(y_bootstrap, y_pred, average='macro', zero_division=1))\n","\n","# Berechne Mittelwert und Standardabweichung der Metriken\n","accuracy_mean = np.mean(accuracy_scores)\n","accuracy_std = np.std(accuracy_scores)\n","precision_mean = np.mean(precision_scores)\n","precision_std = np.std(precision_scores)\n","recall_mean = np.mean(recall_scores)\n","recall_std = np.std(recall_scores)\n","f1_mean = np.mean(f1_scores)\n","f1_std = np.std(f1_scores)\n","\n","print(\"Ergebnisse für Random Forest auf Testdaten mit Bootstrapping:\")\n","print(f\"Accuracy: {accuracy_mean:.4f} (+/- {accuracy_std:.4f})\")\n","print(f\"Precision: {precision_mean:.4f} (+/- {precision_std:.4f})\")\n","print(f\"Recall: {recall_mean:.4f} (+/- {recall_std:.4f})\")\n","print(f\"F1-Score: {f1_mean:.4f} (+/- {f1_std:.4f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2DdtlYeaGHS","executionInfo":{"status":"ok","timestamp":1743259834172,"user_tz":-60,"elapsed":14805,"user":{"displayName":"Sebastian Steininger","userId":"02820484620863115156"}},"outputId":"579a7b60-8d64-4ba1-beaa-f7c8c0504571"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ergebnisse für Random Forest auf Testdaten mit Bootstrapping:\n","Accuracy: 0.9711 (+/- 0.0131)\n","Precision: 0.9739 (+/- 0.0122)\n","Recall: 0.9640 (+/- 0.0165)\n","F1-Score: 0.9683 (+/- 0.0143)\n"]}]}]}