{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMBeb2wDavlY12eAnSBOHA4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import string\n","\n","def generate_char_alphabet_and_translation(corpus_text):\n","  \"\"\"\n","  Generiert ein zeichenbasiertes Alphabet und eine Übersetzungstabelle\n","  basierend auf einem gegebenen Textkorpus.\n","\n","  Args:\n","    corpus_text (str): Der Textkorpus.\n","\n","  Returns:\n","    tuple: Ein Tupel, das Folgendes enthält:\n","      - set: Das Alphabet (ein Set eindeutiger Zeichen).\n","      - dict: Die Übersetzungstabelle (Zeichen zu Index).\n","  \"\"\"\n","  alphabet = set(corpus_text)\n","\n","  char_to_index = {char: i for i, char in enumerate(sorted(list(alphabet)))}\n","  return alphabet, char_to_index\n","\n","def generate_word_alphabet_and_translation(corpus_text):\n","  \"\"\"\n","  Generiert ein wortbasiertes Alphabet und eine Übersetzungstabelle\n","  basierend auf einem gegebenen Textkorpus.\n","\n","  Args:\n","    corpus_text (str): Der Textkorpus.\n","\n","  Returns:\n","    tuple: Ein Tupel, das Folgendes enthält:\n","      - set: Das Alphabet (ein Set eindeutiger Wörter).\n","      - dict: Die Übersetzungstabelle (Wort zu Index).\n","  \"\"\"\n","\n","  # Einfache Worttokenisierung (kann durch komplexere Tokenizer ersetzt werden)\n","  words = corpus_text.lower().split()\n","  alphabet = set(words)\n","\n","  word_to_index = {word: i for i, word in enumerate(sorted(list(alphabet)))}\n","  return alphabet, word_to_index"],"metadata":{"id":"UbCw26ry2h0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_char_alphabet_and_translation(\"Hello World!!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i8Yzrm3422V8","executionInfo":{"status":"ok","timestamp":1749945855434,"user_tz":-120,"elapsed":43,"user":{"displayName":"Sebastian Steininger","userId":"02820484620863115156"}},"outputId":"32673e73-1b94-4a90-f4a7-0185f8309e92"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({' ', '!', 'H', 'W', 'd', 'e', 'l', 'o', 'r'},\n"," {' ': 0, '!': 1, 'H': 2, 'W': 3, 'd': 4, 'e': 5, 'l': 6, 'o': 7, 'r': 8})"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["generate_word_alphabet_and_translation(\"Ich lerne gerne viel über die schöne Welt der KI\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m33SWajv2-Jp","executionInfo":{"status":"ok","timestamp":1749945855474,"user_tz":-120,"elapsed":42,"user":{"displayName":"Sebastian Steininger","userId":"02820484620863115156"}},"outputId":"fdc68678-d692-4163-a3a0-18289c5072e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'der',\n","  'die',\n","  'gerne',\n","  'ich',\n","  'ki',\n","  'lerne',\n","  'schöne',\n","  'viel',\n","  'welt',\n","  'über'},\n"," {'der': 0,\n","  'die': 1,\n","  'gerne': 2,\n","  'ich': 3,\n","  'ki': 4,\n","  'lerne': 5,\n","  'schöne': 6,\n","  'viel': 7,\n","  'welt': 8,\n","  'über': 9})"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XcHSUmgqZATn","executionInfo":{"status":"ok","timestamp":1749945858500,"user_tz":-120,"elapsed":3034,"user":{"displayName":"Sebastian Steininger","userId":"02820484620863115156"}},"outputId":"ee8295cb-3f92-43bb-8a39-bc3eae3bbcfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Lade Datei von https://downloads.wortschatz-leipzig.de/corpora/deu_mixed-typical_2011_10K.tar.gz herunter...\n","Download abgeschlossen.\n","Entpacke Datei deu_mixed-typical_2011_10K.tar.gz...\n","Entpacken abgeschlossen.\n","Extrahiere Text aus deu_mixed-typical_2011_10K-sentences.txt...\n","Textextraktion abgeschlossen.\n"]}],"source":["import requests\n","import tarfile\n","import os\n","\n","url = \"https://downloads.wortschatz-leipzig.de/corpora/deu_mixed-typical_2011_10K.tar.gz\"\n","filename = \"deu_mixed-typical_2011_10K.tar.gz\"\n","extracted_dir = \"deu_mixed-typical_2011_10K\"\n","text_file_name = \"deu_mixed-typical_2011_10K-sentences.txt\"\n","\n","# 1. Datei herunterladen\n","print(f\"Lade Datei von {url} herunter...\")\n","response = requests.get(url, stream=True)\n","if response.status_code == 200:\n","  with open(filename, 'wb') as f:\n","    f.write(response.raw.read())\n","  print(\"Download abgeschlossen.\")\n","else:\n","  print(f\"Fehler beim Herunterladen: Statuscode {response.status_code}\")\n","\n","# 2. Datei entpacken\n","print(f\"Entpacke Datei {filename}...\")\n","if os.path.exists(filename):\n","  with tarfile.open(filename, \"r:gz\") as tar:\n","    tar.extractall(\".\")\n","  print(\"Entpacken abgeschlossen.\")\n","else:\n","  print(f\"Fehler: Datei {filename} nicht gefunden.\")\n","\n","# 3. Text extrahieren\n","print(f\"Extrahiere Text aus {text_file_name}...\")\n","full_text = \"\"\n","file_path = os.path.join(extracted_dir, text_file_name)\n","\n","if os.path.exists(file_path):\n","  with open(file_path, 'r', encoding='utf-8') as f:\n","    for line in f:\n","      # Zeilenaufbau: Zeilennummer + Tab + Text\n","      parts = line.strip().split('\\t', 1)\n","      if len(parts) > 1:\n","        full_text += parts[1] + \" \" # Füge den Text und ein Leerzeichen hinzu\n","  print(\"Textextraktion abgeschlossen.\")\n","else:\n","  print(f\"Fehler: Textdatei {file_path} nicht gefunden. Bitte prüfen Sie den Dateinamen im Tar-Archiv.\")\n"]},{"cell_type":"code","source":["from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers import pre_tokenizers\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n","\n","bpe_tokenizer = Tokenizer(BPE())\n","\n","# Hier definieren wir, dass wir gerne mit dem Byte-Level Vor-Tokenisierer arbeiten\n","# würden. Dieser soll auch sicherstellen, dass jedes Wort mit einem Ġ startet.\n","bpe_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n","\n","bpe_tokenizer.decoder = ByteLevelDecoder()\n","\n","corpus = [full_text]\n","\n","trainer = BpeTrainer(\n","    vocab_size=10000, # Hier definieren wir wie lange trainiert werden soll.\n","    min_frequency=1, # Erlaubt es, dass die bytes für Umlaute zusammengefast werden können.\n","    show_progress=True,\n","    # Diese speziellen Token bleiben erhalten und kennzeichnen besondere Stellen und\n","    # Zeichen im Text. Wie etwa unbekannte Zeichen mit [UNK] oder den Start oder\n","    # Das Ende einer Zeichenkette.\n","    special_tokens=[\"[UNK]\", \"[BOS]\", \"[EOS]\", \"[PAD]\", \"[CLS]\", \"[SEP]\"],\n","    initial_alphabet=pre_tokenizers.ByteLevel.alphabet()\n",")\n","\n","bpe_tokenizer.train_from_iterator(\n","    corpus,\n","    trainer=trainer\n",")\n","\n","print(\"Tokenizer training complete!\")\n","\n","text_to_encode = \"Ich lerne gerne viel über die schöne Welt der KI!\"\n","\n","encoded_text = bpe_tokenizer.encode(text_to_encode).tokens\n","encoded_ids = bpe_tokenizer.encode(text_to_encode).ids\n","\n","print(f\"\\nOriginal text: {text_to_encode}\")\n","print(f\"Encoded text (BPE tokens): {encoded_text}\")\n","print(f\"Encoded text (BPE IDs): {encoded_ids}\")\n","\n","decoded_text = bpe_tokenizer.decode(encoded_ids)\n","print(f\"Decoded text: {decoded_text}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wL3kjrxVNyvX","executionInfo":{"status":"ok","timestamp":1749945861601,"user_tz":-120,"elapsed":3083,"user":{"displayName":"Sebastian Steininger","userId":"02820484620863115156"}},"outputId":"68c2bcb9-fa75-4760-cee8-9fccb2ad8280"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizer training complete!\n","\n","Original text: Ich lerne gerne viel über die schöne Welt der KI!\n","Encoded text (BPE tokens): ['ĠIch', 'Ġl', 'er', 'ne', 'Ġgerne', 'Ġviel', 'ĠÃ¼ber', 'Ġdie', 'ĠschÃ¶ne', 'ĠWelt', 'Ġder', 'ĠK', 'I', '!']\n","Encoded text (BPE IDs): [670, 406, 262, 427, 2703, 993, 465, 292, 4786, 954, 294, 319, 46, 6]\n","Decoded text:  Ich lerne gerne viel über die schöne Welt der KI!\n"]}]}]}