{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjATTgnUN0Ko"
      },
      "outputs": [],
      "source": [
        "def build_bigram_model(text):\n",
        "    # Text in Wörter aufteilen\n",
        "    words = text.split()\n",
        "\n",
        "    # Bigramm-Zählungen initialisieren\n",
        "    bigram_counts = {}\n",
        "\n",
        "    # Durch alle aufeinanderfolgenden Wortpaare iterieren\n",
        "    for i in range(len(words) - 1):\n",
        "        current_word = words[i]\n",
        "        next_word = words[i + 1]\n",
        "\n",
        "        # Wenn das aktuelle Wort noch nicht im Dictionary ist, füge es hinzu\n",
        "        if current_word not in bigram_counts:\n",
        "            bigram_counts[current_word] = {}\n",
        "\n",
        "        # Erhöhe die Zählung für das Folgwort\n",
        "        if next_word not in bigram_counts[current_word]:\n",
        "            bigram_counts[current_word][next_word] = 1\n",
        "        else:\n",
        "            bigram_counts[current_word][next_word] += 1\n",
        "\n",
        "    return bigram_counts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_bigram_model(\"Die Sonne scheint. Die Wolken ziehen vorbei. Die Sonne wärmt.\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iub6jrQ-N6mL",
        "outputId": "eb5a7641-45a0-42ce-dd2f-d24c445e7cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Die': {'Sonne': 2, 'Wolken': 1}, 'Sonne': {'scheint.': 1, 'wärmt.': 1}, 'scheint.': {'Die': 1}, 'Wolken': {'ziehen': 1}, 'ziehen': {'vorbei.': 1}, 'vorbei.': {'Die': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die obrige Implementierung hat den Nachteil, dass Satzzeichen so behandelt werden als wären diese ein Teil des Wortes. In der einfachen Aufgabe muss Schrödinger diese entfernen."
      ],
      "metadata": {
        "id": "DrgoOeYpQcBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_bigram_model(text):\n",
        "    # Satzzeichen als eigenes Wort erkennen, indem wir ein Leerzeichen voranstellen.\n",
        "    for punct in \".,!?;:()[]{}\\\"'\":\n",
        "        text = text.replace(punct, f\" {punct} \")\n",
        "\n",
        "    # Text in Wörter aufteilen\n",
        "    words = text.split()\n",
        "\n",
        "    # Bigramm-Zählungen initialisieren\n",
        "    bigram_counts = {}\n",
        "\n",
        "    # Durch alle aufeinanderfolgenden Wortpaare iterieren\n",
        "    for i in range(len(words) - 1):\n",
        "        current_word = words[i]\n",
        "        next_word = words[i + 1]\n",
        "\n",
        "        # Wenn das aktuelle Wort noch nicht im Dictionary ist, füge es hinzu\n",
        "        if current_word not in bigram_counts:\n",
        "            bigram_counts[current_word] = {}\n",
        "\n",
        "        # Erhöhe die Zählung für das Folgwort\n",
        "        if next_word not in bigram_counts[current_word]:\n",
        "            bigram_counts[current_word][next_word] = 1\n",
        "        else:\n",
        "            bigram_counts[current_word][next_word] += 1\n",
        "\n",
        "    return bigram_counts\n",
        "\n",
        "model = build_bigram_model(\"Die Sonne scheint. Die Wolken ziehen vorbei. Die Sonne wärmt.\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA_FF6gaQZRh",
        "outputId": "c30fe8c3-93c3-4c95-eee5-a772dc378472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Die': {'Sonne': 2, 'Wolken': 1}, 'Sonne': {'scheint': 1, 'wärmt': 1}, 'scheint': {'.': 1}, '.': {'Die': 2}, 'Wolken': {'ziehen': 1}, 'ziehen': {'vorbei': 1}, 'vorbei': {'.': 1}, 'wärmt': {'.': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_bigram_probabilities(bigram_counts):\n",
        "    bigram_probabilities = {}\n",
        "\n",
        "    for current_word, next_words in bigram_counts.items():\n",
        "        # Gesamtzahl der Vorkommen des aktuellen Wortes berechnen\n",
        "        total_count = sum(next_words.values())\n",
        "\n",
        "        # Dictionary für Wahrscheinlichkeiten initialisieren\n",
        "        bigram_probabilities[current_word] = {}\n",
        "\n",
        "        # Wahrscheinlichkeiten für jedes Folgwort berechnen\n",
        "        for next_word, count in next_words.items():\n",
        "            bigram_probabilities[current_word][next_word] = count / total_count\n",
        "\n",
        "    return bigram_probabilities\n",
        "\n",
        "print(calculate_bigram_probabilities(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tQF8vTORgLk",
        "outputId": "8d5d09a2-0913-444f-bbc5-f0e7ad52c369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Die': {'Sonne': 0.6666666666666666, 'Wolken': 0.3333333333333333}, 'Sonne': {'scheint': 0.5, 'wärmt': 0.5}, 'scheint': {'.': 1.0}, '.': {'Die': 1.0}, 'Wolken': {'ziehen': 1.0}, 'ziehen': {'vorbei': 1.0}, 'vorbei': {'.': 1.0}, 'wärmt': {'.': 1.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(bigram_probabilities, current_word):\n",
        "    if current_word not in bigram_probabilities:\n",
        "        return \"Unbekanntes Wort\", 0.0\n",
        "\n",
        "    next_words = bigram_probabilities[current_word]\n",
        "    most_likely_word = max(next_words.items(), key=lambda x: x[1])\n",
        "\n",
        "    return most_likely_word\n",
        "\n",
        "print(predict_next_word(model, \"Die\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLy_gnbxXWuk",
        "outputId": "011744fe-c7ff-4ab0-8c18-226089f91de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Sonne', 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_next_words(bigram_probabilities, current_word, n=3):\n",
        "    if current_word not in bigram_probabilities:\n",
        "        return [(\"Unbekanntes Wort\", 0.0)]\n",
        "\n",
        "    next_words = bigram_probabilities[current_word]\n",
        "    sorted_words = sorted(next_words.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return sorted_words[:n]\n",
        "print(suggest_next_words(model, \"Die\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLA_RQHiYHG3",
        "outputId": "0c4cc627-1f8b-4686-de18-aeb312514f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Sonne', 2), ('Wolken', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_autocomplete():\n",
        "    # Beispieltext zum Trainieren\n",
        "    training_text = \"\"\"Künstliche Intelligenz ist ein faszinierendes Forschungsgebiet.\n",
        "    Künstliche Neuronen bilden die Grundlage für neuronale Netze.\n",
        "    Intelligenz kann in verschiedenen Formen auftreten.\n",
        "    Python ist eine beliebte Programmiersprache für maschinelles Lernen.\n",
        "    Programmiersprache Python wird oft für Data Science verwendet.\n",
        "    Maschinelles Lernen ermöglicht Computern, aus Daten zu lernen.\"\"\"\n",
        "\n",
        "    # Bigramm-Modell bauen\n",
        "    bigram_counts = build_bigram_model(training_text)\n",
        "    bigram_probs = calculate_bigram_probabilities(bigram_counts)\n",
        "\n",
        "    # Interaktive Schleife für Autovervollständigung\n",
        "    print(\"Einfache Autovervollständigung (Beenden mit 'exit')\")\n",
        "    while True:\n",
        "        user_input = input(\"Gib ein Wort ein: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        suggestions = suggest_next_words(bigram_probs, user_input)\n",
        "        print(\"Vorschläge:\")\n",
        "        for word, prob in suggestions:\n",
        "            print(f\"  {word} ({prob:.2f})\")\n",
        "simple_autocomplete()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5JJmhnfYjg-",
        "outputId": "ad708da9-cdec-4e26-bac9-a3dee6c34730"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Einfache Autovervollständigung (Beenden mit 'exit')\n",
            "Gib ein Wort ein: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_smoothed_probabilities(bigram_counts):\n",
        "    smoothed_probabilities = {}\n",
        "\n",
        "    # Erstelle ein Vokabular aller im Modell vorkommenden Wörter\n",
        "    vocabulary = set()\n",
        "    for current_word, next_words in bigram_counts.items():\n",
        "        vocabulary.add(current_word)\n",
        "        for next_word in next_words:\n",
        "            vocabulary.add(next_word)\n",
        "\n",
        "    vocab_size = len(vocabulary)\n",
        "\n",
        "    # Für jedes Wort im Vokabular\n",
        "    for current_word in vocabulary:\n",
        "        # Dictionary für Wahrscheinlichkeiten initialisieren\n",
        "        smoothed_probabilities[current_word] = {}\n",
        "\n",
        "        # Gesamtzahl der Vorkommen des aktuellen Wortes + Vokabulargröße für Add-One-Smoothing\n",
        "        total_count = sum(bigram_counts.get(current_word, {}).values()) + vocab_size\n",
        "\n",
        "        # Für jedes mögliche Folgwort im Vokabular\n",
        "        for next_word in vocabulary:\n",
        "            # Zählung abrufen (0 wenn nicht gesehen)\n",
        "            count = bigram_counts.get(current_word, {}).get(next_word, 0)\n",
        "            # Geglättete Wahrscheinlichkeit berechnen\n",
        "            smoothed_probabilities[current_word][next_word] = (count + 1) / total_count\n",
        "\n",
        "    return smoothed_probabilities\n",
        "print(calculate_smoothed_probabilities(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLL4pEyOVjWk",
        "outputId": "39d39989-439a-4713-de57-74217480d98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Wolken': {'Wolken': 0.1111111111111111, 'Die': 0.1111111111111111, 'wärmt': 0.1111111111111111, 'vorbei': 0.1111111111111111, '.': 0.1111111111111111, 'ziehen': 0.2222222222222222, 'scheint': 0.1111111111111111, 'Sonne': 0.1111111111111111}, 'Die': {'Wolken': 0.18181818181818182, 'Die': 0.09090909090909091, 'wärmt': 0.09090909090909091, 'vorbei': 0.09090909090909091, '.': 0.09090909090909091, 'ziehen': 0.09090909090909091, 'scheint': 0.09090909090909091, 'Sonne': 0.2727272727272727}, 'wärmt': {'Wolken': 0.1111111111111111, 'Die': 0.1111111111111111, 'wärmt': 0.1111111111111111, 'vorbei': 0.1111111111111111, '.': 0.2222222222222222, 'ziehen': 0.1111111111111111, 'scheint': 0.1111111111111111, 'Sonne': 0.1111111111111111}, 'vorbei': {'Wolken': 0.1111111111111111, 'Die': 0.1111111111111111, 'wärmt': 0.1111111111111111, 'vorbei': 0.1111111111111111, '.': 0.2222222222222222, 'ziehen': 0.1111111111111111, 'scheint': 0.1111111111111111, 'Sonne': 0.1111111111111111}, '.': {'Wolken': 0.1, 'Die': 0.3, 'wärmt': 0.1, 'vorbei': 0.1, '.': 0.1, 'ziehen': 0.1, 'scheint': 0.1, 'Sonne': 0.1}, 'ziehen': {'Wolken': 0.1111111111111111, 'Die': 0.1111111111111111, 'wärmt': 0.1111111111111111, 'vorbei': 0.2222222222222222, '.': 0.1111111111111111, 'ziehen': 0.1111111111111111, 'scheint': 0.1111111111111111, 'Sonne': 0.1111111111111111}, 'scheint': {'Wolken': 0.1111111111111111, 'Die': 0.1111111111111111, 'wärmt': 0.1111111111111111, 'vorbei': 0.1111111111111111, '.': 0.2222222222222222, 'ziehen': 0.1111111111111111, 'scheint': 0.1111111111111111, 'Sonne': 0.1111111111111111}, 'Sonne': {'Wolken': 0.1, 'Die': 0.1, 'wärmt': 0.2, 'vorbei': 0.1, '.': 0.1, 'ziehen': 0.1, 'scheint': 0.2, 'Sonne': 0.1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_character_bigram_model(text):\n",
        "    # Bigramm-Zählungen initialisieren\n",
        "    char_bigram_counts = {}\n",
        "\n",
        "    # Durch alle aufeinanderfolgenden Zeichenpaare iterieren\n",
        "    for i in range(len(text) - 1):\n",
        "        current_char = text[i]\n",
        "        next_char = text[i + 1]\n",
        "\n",
        "        # Wenn das aktuelle Zeichen noch nicht im Dictionary ist, füge es hinzu\n",
        "        if current_char not in char_bigram_counts:\n",
        "            char_bigram_counts[current_char] = {}\n",
        "\n",
        "        # Erhöhe die Zählung für das Folgezeichen\n",
        "        if next_char not in char_bigram_counts[current_char]:\n",
        "            char_bigram_counts[current_char][next_char] = 1\n",
        "        else:\n",
        "            char_bigram_counts[current_char][next_char] += 1\n",
        "\n",
        "    return char_bigram_counts\n",
        "\n",
        "print(build_character_bigram_model(\"Die Sonne scheint. Die Wolken ziehen vorbei. Die Sonne wärmt.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWvN-flxKP8A",
        "outputId": "0dc78d1a-5339-4c79-a60b-0890824bb433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'D': {'i': 3}, 'i': {'e': 4, 'n': 1, '.': 1}, 'e': {' ': 5, 'i': 2, 'n': 2, 'h': 1}, ' ': {'S': 2, 's': 1, 'D': 2, 'W': 1, 'z': 1, 'v': 1, 'w': 1}, 'S': {'o': 2}, 'o': {'n': 2, 'l': 1, 'r': 1}, 'n': {'n': 2, 'e': 2, 't': 1, ' ': 2}, 's': {'c': 1}, 'c': {'h': 1}, 'h': {'e': 2}, 't': {'.': 2}, '.': {' ': 2}, 'W': {'o': 1}, 'l': {'k': 1}, 'k': {'e': 1}, 'z': {'i': 1}, 'v': {'o': 1}, 'r': {'b': 1, 'm': 1}, 'b': {'e': 1}, 'w': {'ä': 1}, 'ä': {'r': 1}, 'm': {'t': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-Gramme beliebiger Größe"
      ],
      "metadata": {
        "id": "GoLejaQcL88P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ngram_model(text, n):\n",
        "    words = text.split()\n",
        "    ngram_counts = {}\n",
        "\n",
        "    # Durch alle möglichen N-Gramme iterieren\n",
        "    for i in range(len(words) - n + 1):\n",
        "        # Die ersten n-1 Wörter sind der Kontext\n",
        "        context = tuple(words[i:i+n-1])\n",
        "        next_word = words[i+n-1]\n",
        "\n",
        "        if context not in ngram_counts:\n",
        "            ngram_counts[context] = {}\n",
        "\n",
        "        if next_word not in ngram_counts[context]:\n",
        "            ngram_counts[context][next_word] = 1\n",
        "        else:\n",
        "            ngram_counts[context][next_word] += 1\n",
        "\n",
        "    return ngram_counts\n",
        "\n",
        "def calculate_smoothed_ngram_probabilities(ngram_counts):\n",
        "    smoothed_probabilities = {}\n",
        "\n",
        "    # Erstelle ein Vokabular aller Wörter im Modell\n",
        "    vocabulary = set()\n",
        "    for context, next_words in ngram_counts.items():\n",
        "        for next_word in next_words:\n",
        "            vocabulary.add(next_word)\n",
        "        # Auch Wörter aus dem Kontext zum Vokabular hinzufügen\n",
        "        vocabulary.update(context)\n",
        "\n",
        "    vocab_size = len(vocabulary)\n",
        "\n",
        "    # Für jeden Kontext\n",
        "    for context, next_words in ngram_counts.items():\n",
        "        # Dictionary für Wahrscheinlichkeiten initialisieren\n",
        "        smoothed_probabilities[context] = {}\n",
        "\n",
        "        # Gesamtzahl der Vorkommen des Kontexts + Vokabulargröße für Add-One-Smoothing\n",
        "        total_count = sum(next_words.values()) + vocab_size\n",
        "\n",
        "        # Für jedes mögliche Folgwort im Vokabular\n",
        "        for next_word in vocabulary:\n",
        "            # Zählung abrufen (0 wenn nicht gesehen)\n",
        "            count = next_words.get(next_word, 0)\n",
        "            # Geglättete Wahrscheinlichkeit berechnen\n",
        "            smoothed_probabilities[context][next_word] = (count + 1) / total_count\n",
        "\n",
        "    return smoothed_probabilities\n",
        "\n",
        "\n",
        "print(calculate_smoothed_ngram_probabilities(build_ngram_model(\"Die Sonne scheint. Die Wolken ziehen vorbei. Die Sonne wärmt.\", 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-BNZeouL8QP",
        "outputId": "47dec333-bec3-436d-aea1-d12db2b30c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('Die', 'Sonne'): {'Wolken': 0.1111111111111111, 'Die': 0.1111111111111111, 'wärmt.': 0.2222222222222222, 'scheint.': 0.2222222222222222, 'ziehen': 0.1111111111111111, 'vorbei.': 0.1111111111111111, 'Sonne': 0.1111111111111111}, ('Sonne', 'scheint.'): {'Wolken': 0.125, 'Die': 0.25, 'wärmt.': 0.125, 'scheint.': 0.125, 'ziehen': 0.125, 'vorbei.': 0.125, 'Sonne': 0.125}, ('scheint.', 'Die'): {'Wolken': 0.25, 'Die': 0.125, 'wärmt.': 0.125, 'scheint.': 0.125, 'ziehen': 0.125, 'vorbei.': 0.125, 'Sonne': 0.125}, ('Die', 'Wolken'): {'Wolken': 0.125, 'Die': 0.125, 'wärmt.': 0.125, 'scheint.': 0.125, 'ziehen': 0.25, 'vorbei.': 0.125, 'Sonne': 0.125}, ('Wolken', 'ziehen'): {'Wolken': 0.125, 'Die': 0.125, 'wärmt.': 0.125, 'scheint.': 0.125, 'ziehen': 0.125, 'vorbei.': 0.25, 'Sonne': 0.125}, ('ziehen', 'vorbei.'): {'Wolken': 0.125, 'Die': 0.25, 'wärmt.': 0.125, 'scheint.': 0.125, 'ziehen': 0.125, 'vorbei.': 0.125, 'Sonne': 0.125}, ('vorbei.', 'Die'): {'Wolken': 0.125, 'Die': 0.125, 'wärmt.': 0.125, 'scheint.': 0.125, 'ziehen': 0.125, 'vorbei.': 0.125, 'Sonne': 0.25}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Back-Off-Modelle"
      ],
      "metadata": {
        "id": "LWRLmu0uPxcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_backoff(trigram_model, bigram_model, unigram_model, context_words):\n",
        "    if len(context_words) >= 2:\n",
        "        # Trigram context\n",
        "        context = tuple(context_words[-2:])\n",
        "        if context in trigram_model and trigram_model[context]:\n",
        "            return max(trigram_model[context].items(), key=lambda x: x[1])\n",
        "\n",
        "    if len(context_words) >= 1:\n",
        "        # Bigram context\n",
        "        context = context_words[-1]\n",
        "        if context in bigram_model and bigram_model[context]:\n",
        "            return max(bigram_model[context].items(), key=lambda x: x[1])\n",
        "\n",
        "    # Unigram (häufigstes Wort)\n",
        "    return max(unigram_model.items(), key=lambda x: x[1])"
      ],
      "metadata": {
        "id": "0Zk5TYHxPwtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Die Schwierige Aufgabe\n",
        "Erweitere die Backoff-Methode um Interpolation, bei der die Vorhersagen verschiedener N-Gramm-Modelle mit Gewichten kombiniert werden."
      ],
      "metadata": {
        "id": "E0AcCsj_RdSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_interpolation(trigram_model, bigram_model, unigram_model, context_words, lambda1=0.7, lambda2=0.2, lambda3=0.1):\n",
        "    # Wahrscheinlichkeiten initialisieren\n",
        "    trigram_prob = {}\n",
        "    bigram_prob = {}\n",
        "    unigram_prob = {}\n",
        "\n",
        "    if len(context_words) >= 2:\n",
        "        # Trigram context\n",
        "        context = tuple(context_words[-2:])\n",
        "        if context in trigram_model and trigram_model[context]:\n",
        "            trigram_prob = trigram_model[context]\n",
        "\n",
        "    if len(context_words) >= 1:\n",
        "        # Bigram context\n",
        "        context = context_words[-1]\n",
        "        if context in bigram_model and bigram_model[context]:\n",
        "            bigram_prob = bigram_model[context]\n",
        "\n",
        "    # Unigram (häufigstes Wort)\n",
        "    unigram_prob = unigram_model.get((), {})\n",
        "\n",
        "    # Interpolierte Wahrscheinlichkeiten berechnen\n",
        "    interpolated_prob = {}\n",
        "    for word in set(trigram_prob.keys()).union(bigram_prob.keys()).union(unigram_prob.keys()):\n",
        "        interpolated_prob[word] = (\n",
        "            lambda1 * trigram_prob.get(word, 0) +\n",
        "            lambda2 * bigram_prob.get(word, 0) +\n",
        "            lambda3 * unigram_prob.get(word, 0)\n",
        "        )\n",
        "\n",
        "    # Vorhersage basierend auf der höchsten interpolierten Wahrscheinlichkeit\n",
        "    return max(interpolated_prob.items(), key=lambda x: x[1])\n",
        "\n",
        "# Beispielaufruf der Funktion\n",
        "training_text = \"\"\"Künstliche Intelligenz ist ein faszinierendes Forschungsgebiet.\n",
        "Künstliche Neuronen bilden die Grundlage für neuronale Netze.\n",
        "Intelligenz kann in verschiedenen Formen auftreten.\n",
        "Python ist eine beliebte Programmiersprache für maschinelles Lernen.\n",
        "Programmiersprache Python wird oft für Data Science verwendet.\n",
        "Maschinelles Lernen ermöglicht Computern, aus Daten zu lernen.\"\"\"\n",
        "\n",
        "trigram_model = calculate_smoothed_ngram_probabilities(build_ngram_model(training_text, 3))\n",
        "bigram_model = calculate_smoothed_ngram_probabilities(build_ngram_model(training_text, 2))\n",
        "unigram_model = calculate_smoothed_ngram_probabilities(build_ngram_model(training_text, 1))\n",
        "context_words = [\"spannendes\", \"Forschungsgebiet\"]\n",
        "prediction = predict_with_interpolation(trigram_model, bigram_model, unigram_model, context_words)\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwDdAu3mRh_K",
        "outputId": "3ce033d5-e0b4-4e35-eb76-67fc334c5de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('für', 0.0049382716049382715)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimierungen"
      ],
      "metadata": {
        "id": "8CSkcaxvqsr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Effizientere Implementierung mit Defaultdict\n",
        "from collections import defaultdict\n",
        "\n",
        "def build_ngram_model_optimized(text, n):\n",
        "    words = text.split()\n",
        "    # Verschachtelte defaultdicts für automatische Initialisierung\n",
        "    ngram_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # Durch alle möglichen N-Gramme iterieren\n",
        "    for i in range(len(words) - n + 1):\n",
        "        # Die ersten n-1 Wörter sind der Kontext\n",
        "        context = tuple(words[i:i+n-1])\n",
        "        next_word = words[i+n-1]\n",
        "\n",
        "        # Mit defaultdict brauchen wir keine Existenzprüfung mehr\n",
        "        ngram_counts[context][next_word] += 1\n",
        "\n",
        "    return ngram_counts\n",
        "\n",
        "def prune_ngram_model(ngram_model, min_count=2):\n",
        "    pruned_model = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for context, next_words in ngram_model.items():\n",
        "        for word, count in next_words.items():\n",
        "            if count >= min_count:\n",
        "                pruned_model[context][word] = count\n",
        "\n",
        "    return pruned_model"
      ],
      "metadata": {
        "id": "C9-TxbcDqucl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJayke5csHB3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}